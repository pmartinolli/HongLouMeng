df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[-]+', ' ', regex=True)
# Replace four space by line break
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[　　]+', '\r\n', regex=True)
# Add chapter numbers as integers
df_cn['Chapter_num'] = range(1, len(df_cn) + 1)
#| code-fold: true
# The echo: false option disables the printing of code (only output is displayed).
with open("fulltext.txt", "r", encoding="utf-8") as file:
main_text = file.read()
#| code-fold: true
import pandas as pd
import re
# Step 1: Split by chapters
# Extract between 第 and 回 when a line starts with 第 and 回 is not more far than 4 positions
chapters = re.split(r'(?=^第.{0,4}回\s*)', main_text, flags=re.MULTILINE)
data = []
for chapter in chapters[1:]:
# Split into title (up to first line break) and content (the rest)
lines = chapter.strip().split('\n', 1)
title = lines[0].strip()
content = lines[1].strip() if len(lines) > 1 else ''
data.append([title, content])
# Create DataFrame
df_cn = pd.DataFrame(data, columns=['Chapter', 'RawContent'])
# Step 2 : Doing some cleaning
# Remove line breaks in the RawContent
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[\r\n]+', ' ', regex=True)
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[\n]+', ' ', regex=True)
# Remove dashes in the RawContent
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[-]+', ' ', regex=True)
# Replace four space by line break
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[　　]+', '\r\n', regex=True)
# Add chapter numbers as integers
df_cn['Chapter_num'] = range(1, len(df_cn) + 1)
#| code-fold: true
# The echo: false option disables the printing of code (only output is displayed).
with open("fulltext.txt", "r", encoding="utf-8") as file:
main_text = file.read()
#| code-fold: true
import pandas as pd
import re
# Step 1: Split by chapters
# Extract between 第 and 回 when a line starts with 第 and 回 is not more far than 4 positions
chapters = re.split(r'(?=^第.{0,4}回\s*)', main_text, flags=re.MULTILINE)
data = []
for chapter in chapters[1:]:
# Split into title (up to first line break) and content (the rest)
lines = chapter.strip().split('\n', 1)
title = lines[0].strip()
content = lines[1].strip() if len(lines) > 1 else ''
data.append([title, content])
# Create DataFrame
df_cn = pd.DataFrame(data, columns=['Chapter', 'RawContent'])
# Step 2 : Doing some cleaning
# Remove line breaks in the RawContent
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[\r\n]+', ' ', regex=True)
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[\n]+', ' ', regex=True)
# Remove dashes in the RawContent
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[-]+', ' ', regex=True)
# Replace four space by line break
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[　　]+', '\r\n', regex=True)
# Add chapter numbers as integers
df_cn['Chapter_num'] = range(1, len(df_cn) + 1)
#| code-fold: true
# Count how many times the three main protagonists are counted in RawContent
# Synonyms are enriched thanks to Wikidata (in labels).
# List of Jia Baoyu's synonyms https://www.wikidata.org/wiki/Q8428650
jia_baoyu_synonyms = [
'贾宝玉', '賈寶玉', '寶玉', '寶二爺', '怡紅公子',
'絳洞花王', '富貴閒人', '宝玉', '宝二爷',
'絳洞花主', '绛洞花主', '怡红公子', '绛洞花王'
]
# Join them into a regex pattern
jia_baoyu_pattern = '|'.join(jia_baoyu_synonyms)
# Use in your count
df_cn['count_JiaBaoyu'] = df_cn['RawContent'].str.count(jia_baoyu_pattern)
# List of Lin Daiyu's synonyms
lin_daiyu_synonyms = [
'林黛玉', '黛玉', '瀟湘妃子', '顰兒', '颦儿',
'林姑娘', '林妹妹', '潇湘妃子'
]
# Join them into a regex pattern
lin_daiyu_pattern = '|'.join(lin_daiyu_synonyms)
# Use in your count
df_cn['count_LinDaiyu'] = df_cn['RawContent'].str.count(lin_daiyu_pattern)
# List of Xue Baochai's synonyms
xue_baochai_synonyms = [
'薛寶釵', '薛宝钗', '寶釵', '宝钗',
'蘅蕪君', '蘅芜君', '寶姑娘', '宝姑娘',
'寶丫頭', '宝丫头', '寶姐姐', '宝姐姐'
]
# Join them into a regex pattern
xue_baochai_pattern = '|'.join(xue_baochai_synonyms)
# Use in your count
df_cn['count_XueBaochai'] = df_cn['RawContent'].str.count(xue_baochai_pattern)
#| label: fig-threemain
#| fig-cap: "Three Main Protagonists"
#| code-fold: true
#Note that we included the cell option fold: true to hide the code by default (click the Code button to show it).
# pip install scikit-learn jieba seaborn matplotlib
# Draw a heat map for each entry and the values of the columns
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['count_JiaBaoyu', 'count_LinDaiyu', 'count_XueBaochai']]
# Create the heatmap
# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
heatmap_data,
annot=False,          # No numbers inside cells
cmap='RdPu',          # palette of colors
linewidths=0.5,
cbar=True,
xticklabels=True,    #  column names
yticklabels=False     # No row labels
)
# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(0, num_rows, 25)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing
plt.title('«Dream of the Red Chamber» Three Main Protagonists \n(Number of Mentions per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('characters_count_hlm.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-pairs
#| fig-cap: "Pairs of Two Protagonists"
#| code-fold: true
# Count how many times there is a jia_baoyu_synonyms AND a lin_daiyu_synonyms within 20/threshold characters.
threshold = 20
# Compile regex patterns (non-capturing groups for clarity)
jia_baoyu_pattern = r'(?:' + '|'.join(jia_baoyu_synonyms) + r')'
lin_daiyu_pattern = r'(?:' + '|'.join(lin_daiyu_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_lin_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}|{lin_daiyu_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_lin_pairs(text):
return len(re.findall(jia_lin_pattern, text))
# Apply to the DataFrame
df_cn['count_jia_lin'] = df_cn['RawContent'].apply(count_jia_lin_pairs)
# count pairs of jia et xue
xue_baochai_pattern = r'(?:' + '|'.join(xue_baochai_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_xue_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_xue_pairs(text):
return len(re.findall(jia_xue_pattern, text))
# Apply to the DataFrame
df_cn['count_jia_xue'] = df_cn['RawContent'].apply(count_jia_xue_pairs)
# count pairs of lin et xue
lin_xue_pattern = rf'{lin_daiyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}'
# Function to count matches in a string
def count_lin_xue_pairs(text):
return len(re.findall(lin_xue_pattern, text))
# Apply to the DataFrame
df_cn['count_lin_xue'] = df_cn['RawContent'].apply(count_lin_xue_pairs)
# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['count_jia_lin', 'count_jia_xue','count_lin_xue']]
# # Create the heatmap
# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
heatmap_data,
annot=False,          # No numbers inside cells
cmap='RdPu',
linewidths=0.5,
cbar=True,
xticklabels=True,    #  column names
yticklabels=False     # No row labels
)
# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(0, num_rows, 25)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing
plt.title('«Dream of the Red Chamber» Pairs of Protagonists \n Mentioned Together (per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('pairs_characters_hlm.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-similarity
#| fig-cap: "Similarity matrix"
#| code-fold: true
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
# Optional: Use jieba to segment Chinese text
def jieba_tokenizer(text):
return jieba.lcut(text)
# Segment Chinese text with jieba
df_cn['Segmented'] = df_cn['RawContent'].apply(lambda x: ' '.join(jieba.lcut(x)))
# TF-IDF Vectorization on segmented text
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df_cn['Segmented'])
# Cosine similarity between chapters
similarity_matrix = cosine_similarity(tfidf_matrix)
# Format as DataFrame for heatmap
similarity_df = pd.DataFrame(
similarity_matrix,
index=[f"Ch{idx+1}" for idx in range(len(df_cn))],
columns=[f"Ch{idx+1}" for idx in range(len(df_cn))]
)
# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(similarity_df,
cmap='RdPu',
vmin=0,
mask=np.eye(similarity_df.shape[0]),
vmax=1,
linewidths=0.2)
plt.title("«Dream of the Red Chamber» Chapter Similarity Matrix")
plt.xlabel("Chapters")
plt.ylabel("Chapters")
plt.tight_layout()
plt.savefig('similarity_matrix.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-pairs
#| fig-cap: "Pairs of Two Protagonists"
#| code-fold: true
# Count how many times there is a jia_baoyu_synonyms AND a lin_daiyu_synonyms within 20/threshold characters.
threshold = 20
# Compile regex patterns (non-capturing groups for clarity)
jia_baoyu_pattern = r'(?:' + '|'.join(jia_baoyu_synonyms) + r')'
lin_daiyu_pattern = r'(?:' + '|'.join(lin_daiyu_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_lin_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}|{lin_daiyu_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_lin_pairs(text):
return len(re.findall(jia_lin_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_LinDaiyu'] = df_cn['RawContent'].apply(count_jia_lin_pairs)
# count pairs of jia et xue
xue_baochai_pattern = r'(?:' + '|'.join(xue_baochai_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_xue_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_xue_pairs(text):
return len(re.findall(jia_xue_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_XueBaochai'] = df_cn['RawContent'].apply(count_jia_xue_pairs)
# count pairs of lin et xue
lin_xue_pattern = rf'{lin_daiyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}'
# Function to count matches in a string
def count_lin_xue_pairs(text):
return len(re.findall(lin_xue_pattern, text))
# Apply to the DataFrame
df_cn['LinDaiyu_XueBaochai'] = df_cn['RawContent'].apply(count_lin_xue_pairs)
# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['JiaBaoyu_LinDaiyu', 'JiaBaoyu_XueBaochai','LinDaiyu_XueBaochai']]
# # Create the heatmap
# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
heatmap_data,
annot=False,          # No numbers inside cells
cmap='RdPu',
linewidths=0.5,
cbar=True,
xticklabels=True,    #  column names
yticklabels=False     # No row labels
)
# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(0, num_rows, 25)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing
plt.title('«Dream of the Red Chamber» Pairs of Protagonists \n Mentioned Together (per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('pairs_characters_hlm.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-pairs
#| fig-cap: "Pairs of Two Protagonists"
#| code-fold: true
# Count how many times there is a jia_baoyu_synonyms AND a lin_daiyu_synonyms within 20/threshold characters.
threshold = 20
# Compile regex patterns (non-capturing groups for clarity)
jia_baoyu_pattern = r'(?:' + '|'.join(jia_baoyu_synonyms) + r')'
lin_daiyu_pattern = r'(?:' + '|'.join(lin_daiyu_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_lin_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}|{lin_daiyu_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_lin_pairs(text):
return len(re.findall(jia_lin_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_LinDaiyu'] = df_cn['RawContent'].apply(count_jia_lin_pairs)
# count pairs of jia et xue
xue_baochai_pattern = r'(?:' + '|'.join(xue_baochai_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_xue_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_xue_pairs(text):
return len(re.findall(jia_xue_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_XueBaochai'] = df_cn['RawContent'].apply(count_jia_xue_pairs)
# count pairs of lin et xue
lin_xue_pattern = rf'{lin_daiyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}'
# Function to count matches in a string
def count_lin_xue_pairs(text):
return len(re.findall(lin_xue_pattern, text))
# Apply to the DataFrame
df_cn['LinDaiyu_XueBaochai'] = df_cn['RawContent'].apply(count_lin_xue_pairs)
# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['JiaBaoyu_LinDaiyu', 'JiaBaoyu_XueBaochai','LinDaiyu_XueBaochai']]
# # Create the heatmap
# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
heatmap_data,
annot=False,          # No numbers inside cells
cmap='RdPu',
linewidths=0.5,
cbar=True,
xticklabels=True,    #  column names
yticklabels=False     # No row labels
)
# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(0, num_rows, 24)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing
plt.title('«Dream of the Red Chamber» Pairs of Protagonists \n Mentioned Together (per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('pairs_characters_hlm.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-pairs
#| fig-cap: "Pairs of Two Protagonists"
#| code-fold: true
# Count how many times there is a jia_baoyu_synonyms AND a lin_daiyu_synonyms within 20/threshold characters.
threshold = 20
# Compile regex patterns (non-capturing groups for clarity)
jia_baoyu_pattern = r'(?:' + '|'.join(jia_baoyu_synonyms) + r')'
lin_daiyu_pattern = r'(?:' + '|'.join(lin_daiyu_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_lin_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}|{lin_daiyu_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_lin_pairs(text):
return len(re.findall(jia_lin_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_LinDaiyu'] = df_cn['RawContent'].apply(count_jia_lin_pairs)
# count pairs of jia et xue
xue_baochai_pattern = r'(?:' + '|'.join(xue_baochai_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_xue_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_xue_pairs(text):
return len(re.findall(jia_xue_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_XueBaochai'] = df_cn['RawContent'].apply(count_jia_xue_pairs)
# count pairs of lin et xue
lin_xue_pattern = rf'{lin_daiyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}'
# Function to count matches in a string
def count_lin_xue_pairs(text):
return len(re.findall(lin_xue_pattern, text))
# Apply to the DataFrame
df_cn['LinDaiyu_XueBaochai'] = df_cn['RawContent'].apply(count_lin_xue_pairs)
# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['JiaBaoyu_LinDaiyu', 'JiaBaoyu_XueBaochai','LinDaiyu_XueBaochai']]
# # Create the heatmap
# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
heatmap_data,
annot=False,          # No numbers inside cells
cmap='RdPu',
linewidths=0.5,
cbar=True,
xticklabels=True,    #  column names
yticklabels=False     # No row labels
)
# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(1, num_rows, 25)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing
plt.title('«Dream of the Red Chamber» Pairs of Protagonists \n Mentioned Together (per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('pairs_characters_hlm.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-pairs
#| fig-cap: "Pairs of Two Protagonists"
#| code-fold: true
# Count how many times there is a jia_baoyu_synonyms AND a lin_daiyu_synonyms within 20/threshold characters.
threshold = 20
# Compile regex patterns (non-capturing groups for clarity)
jia_baoyu_pattern = r'(?:' + '|'.join(jia_baoyu_synonyms) + r')'
lin_daiyu_pattern = r'(?:' + '|'.join(lin_daiyu_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_lin_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}|{lin_daiyu_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_lin_pairs(text):
return len(re.findall(jia_lin_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_LinDaiyu'] = df_cn['RawContent'].apply(count_jia_lin_pairs)
# count pairs of jia et xue
xue_baochai_pattern = r'(?:' + '|'.join(xue_baochai_synonyms) + r')'
# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_xue_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'
# Function to count matches in a string
def count_jia_xue_pairs(text):
return len(re.findall(jia_xue_pattern, text))
# Apply to the DataFrame
df_cn['JiaBaoyu_XueBaochai'] = df_cn['RawContent'].apply(count_jia_xue_pairs)
# count pairs of lin et xue
lin_xue_pattern = rf'{lin_daiyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}'
# Function to count matches in a string
def count_lin_xue_pairs(text):
return len(re.findall(lin_xue_pattern, text))
# Apply to the DataFrame
df_cn['LinDaiyu_XueBaochai'] = df_cn['RawContent'].apply(count_lin_xue_pairs)
# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['JiaBaoyu_LinDaiyu', 'JiaBaoyu_XueBaochai','LinDaiyu_XueBaochai']]
# # Create the heatmap
# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
heatmap_data,
annot=False,          # No numbers inside cells
cmap='RdPu',
linewidths=0.5,
cbar=True,
xticklabels=True,    #  column names
yticklabels=False     # No row labels
)
# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(0, num_rows, 25)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing
plt.title('«Dream of the Red Chamber» Pairs of Protagonists \n Mentioned Together (per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('pairs_characters_hlm.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-similarity
#| fig-cap: "Similarity matrix"
#| code-fold: true
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
# Optional: Use jieba to segment Chinese text
def jieba_tokenizer(text):
return jieba.lcut(text)
# Segment Chinese text with jieba
df_cn['Segmented'] = df_cn['RawContent'].apply(lambda x: ' '.join(jieba.lcut(x)))
# TF-IDF Vectorization on segmented text
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df_cn['Segmented'])
# Cosine similarity between chapters
similarity_matrix = cosine_similarity(tfidf_matrix)
# Format as DataFrame for heatmap
similarity_df = pd.DataFrame(
similarity_matrix,
index=[f"{idx+1}" for idx in range(len(df_cn))],
columns=[f"{idx+1}" for idx in range(len(df_cn))]
)
# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(similarity_df,
cmap='RdPu',
vmin=0,
mask=np.eye(similarity_df.shape[0]),
vmax=1,
linewidths=0.2)
plt.title("«Dream of the Red Chamber» Chapter Similarity Matrix")
plt.xlabel("Chapters")
plt.ylabel("Chapters")
plt.tight_layout()
plt.savefig('similarity_matrix.png', dpi=300, bbox_inches='tight')
plt.show()
#| label: fig-similarity
#| fig-cap: "Similarity matrix"
#| code-fold: true
#| echo: false
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
# Optional: Use jieba to segment Chinese text
def jieba_tokenizer(text):
return jieba.lcut(text)
# Segment Chinese text with jieba
df_cn['Segmented'] = df_cn['RawContent'].apply(lambda x: ' '.join(jieba.lcut(x)))
# TF-IDF Vectorization on segmented text
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df_cn['Segmented'])
# Cosine similarity between chapters
similarity_matrix = cosine_similarity(tfidf_matrix)
# Format as DataFrame for heatmap
similarity_df = pd.DataFrame(
similarity_matrix,
index=[f"{idx+1}" for idx in range(len(df_cn))],
columns=[f"{idx+1}" for idx in range(len(df_cn))]
)
# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(similarity_df,
cmap='RdPu',
vmin=0,
mask=np.eye(similarity_df.shape[0]),
vmax=1,
linewidths=0.2)
plt.title("«Dream of the Red Chamber» Chapter Similarity Matrix")
plt.xlabel("Chapters")
plt.ylabel("Chapters")
plt.tight_layout()
plt.savefig('similarity_matrix.png', dpi=300, bbox_inches='tight')
plt.show()
