---
title: "Dream of the Red Chamber Data visualizations"
subtitle: ""
lang: en
author:
      - name: "Pascal Martinolli"
        orcid: "0000-0003-0122-5300"
        affiliation: "Independent researcher"
date: "2025-04-24"
abstract: "Data visualization of the three main protagonists of 红楼梦 (Dream of the Red Chamber), a classic of Chinese literature. It represents their mentions along the 120 chapters of the novel."
keywords: "dataviz; data visualization; Dream of the Red Chamber; 红楼梦"
---

## Introduction

It's a data visualization of the three main protagonists of 红楼梦 ([*Dream of the Red Chamber*](https://en.wikipedia.org/wiki/Dream_of_the_Red_Chamber)), a classic of Chinese literature. It represents their mentions along the 120 chapters of the novel.

This page is the result of some experimentations I made to try Python in a Quarto environment with jupyter.

## Importing data

Importing **fulltext.txt**, a text file retrieved from [Project Gutenberg](https://www.gutenberg.org/ebooks/24264). It is written with traditionnal chinese characters. The header with metadata and the end notes with legal information were removed. Some minor typos were corrected to allow a good splitting.

```{python}
#| code-fold: true

# The echo: false option disables the printing of code (only output is displayed).

with open("fulltext.txt", "r", encoding="utf-8") as file:
    main_text = file.read()
```

Putting the content into a panda dataframe and shampooing the data :

```{python}
#| code-fold: true

import pandas as pd
import re

# Step 1: Split by chapters
# Extract between 第 and 回 when a line starts with 第 and 回 is not more far than 4 positions

chapters = re.split(r'(?=^第.{0,4}回\s*)', main_text, flags=re.MULTILINE)
data = []

for chapter in chapters[1:]:
    # Split into title (up to first line break) and content (the rest)
    lines = chapter.strip().split('\n', 1)
    title = lines[0].strip()
    content = lines[1].strip() if len(lines) > 1 else ''
    data.append([title, content])


# Create DataFrame
df_cn = pd.DataFrame(data, columns=['Chapter', 'RawContent'])



# Step 2 : Doing some cleaning 

# Remove line breaks in the RawContent
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[\r\n]+', ' ', regex=True)
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[\n]+', ' ', regex=True)

# Remove dashes in the RawContent
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[-]+', ' ', regex=True)

# Replace four space by line break
df_cn['RawContent'] = df_cn['RawContent'].str.replace(r'[　　]+', '\r\n', regex=True)

# Add chapter numbers as integers
df_cn['Chapter_num'] = range(1, len(df_cn) + 1)
```

## How many times the 3 mains protogonists are mentioned

### Counting

```{python}
#| code-fold: true

# Count how many times the three main protagonists are counted in RawContent
# Synonyms are enriched thanks to Wikidata (in labels).

# List of Jia Baoyu's synonyms https://www.wikidata.org/wiki/Q8428650
jia_baoyu_synonyms = [
    '贾宝玉', '賈寶玉', '寶玉', '寶二爺', '怡紅公子',
    '絳洞花王', '富貴閒人', '宝玉', '宝二爷', 
    '絳洞花主', '绛洞花主', '怡红公子', '绛洞花王'
]

# Join them into a regex pattern
jia_baoyu_pattern = '|'.join(jia_baoyu_synonyms)

# Use in your count
df_cn['count_JiaBaoyu'] = df_cn['RawContent'].str.count(jia_baoyu_pattern)




# List of Lin Daiyu's synonyms
lin_daiyu_synonyms = [
    '林黛玉', '黛玉', '瀟湘妃子', '顰兒', '颦儿',
    '林姑娘', '林妹妹', '潇湘妃子'
]

# Join them into a regex pattern
lin_daiyu_pattern = '|'.join(lin_daiyu_synonyms)

# Use in your count
df_cn['count_LinDaiyu'] = df_cn['RawContent'].str.count(lin_daiyu_pattern)




# List of Xue Baochai's synonyms
xue_baochai_synonyms = [
    '薛寶釵', '薛宝钗', '寶釵', '宝钗',
    '蘅蕪君', '蘅芜君', '寶姑娘', '宝姑娘',
    '寶丫頭', '宝丫头', '寶姐姐', '宝姐姐'
]

# Join them into a regex pattern
xue_baochai_pattern = '|'.join(xue_baochai_synonyms)

# Use in your count
df_cn['count_XueBaochai'] = df_cn['RawContent'].str.count(xue_baochai_pattern)
```

### Drawing a heatmap

Plotting a heatmap for all the chapters with a different color intensity depending on how many times one of the three main protagonists are mentioned.

```{python}
#| label: fig-threemain
#| fig-cap: "Three Main Protagonists"
#| code-fold: true

#Note that we included the cell option fold: true to hide the code by default (click the Code button to show it).

# pip install scikit-learn jieba seaborn matplotlib

# Draw a heat map for each entry and the values of the columns 

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['count_JiaBaoyu', 'count_LinDaiyu', 'count_XueBaochai']]


# Create the heatmap

# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
    heatmap_data,
    annot=False,          # No numbers inside cells
    cmap='RdPu',          # palette of colors
    linewidths=0.5,
    cbar=True,
    xticklabels=True,    #  column names
    yticklabels=False     # No row labels
)

# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(0, num_rows, 25)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing

plt.title('«Dream of the Red Chamber» Three Main Protagonists \n(Number of Mentions per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('characters_count_hlm.png', dpi=300, bbox_inches='tight')
plt.show()


```

### Drawing a stacked bars graph

```{python}
#| label: fig-threemain-bars1
#| fig-cap: "Three Main Protagonists"
#| code-fold: true

# Set up data
chapter_nums = df_cn['Chapter_num']
counts_baoyu = df_cn['count_JiaBaoyu']
counts_daiyu = df_cn['count_LinDaiyu']
counts_baochai = df_cn['count_XueBaochai']

# Set figure size
plt.figure(figsize=(12, 6))

# Plot stacked bars
plt.bar(chapter_nums, counts_baoyu, label='Jia Baoyu', color='mediumvioletred')
plt.bar(chapter_nums, counts_daiyu, bottom=counts_baoyu, label='Lin Daiyu', color='orchid')
plt.bar(
    chapter_nums,
    counts_baochai,
    bottom=counts_baoyu + counts_daiyu,
    label='Xue Baochai',
    color='plum'
)

# Labels and legend
plt.title('«Dream of the Red Chamber» Three Main Protagonists\n(Number of Mentions per Chapter)')
plt.xlabel('Chapter Number')
plt.ylabel('Number of Mentions')
plt.legend()
plt.tight_layout()

# Save and show
plt.savefig('characters_count_stackedbars.png', dpi=300, bbox_inches='tight')
plt.show()

```

### Another one

```{python}
#| label: fig-threemain-bars2
#| fig-cap: "Three Main Protagonists"
#| code-fold: true

# Set up data
chapter_nums = df_cn['Chapter_num']
counts_baoyu = df_cn['count_JiaBaoyu']
counts_daiyu = df_cn['count_LinDaiyu']
counts_baochai = df_cn['count_XueBaochai']

# Set figure and axes
fig, axs = plt.subplots(3, 1, figsize=(12, 10), sharex=True)

# Jia Baoyu
axs[0].bar(chapter_nums, counts_baoyu, color='mediumvioletred')
axs[0].set_title('Jia Baoyu – Number of Mentions per Chapter')
axs[0].set_ylabel('Mentions')

# Lin Daiyu
axs[1].bar(chapter_nums, counts_daiyu, color='orchid')
axs[1].set_title('Lin Daiyu – Number of Mentions per Chapter')
axs[1].set_ylabel('Mentions')

# Xue Baochai
axs[2].bar(chapter_nums, counts_baochai, color='plum')
axs[2].set_title('Xue Baochai – Number of Mentions per Chapter')
axs[2].set_ylabel('Mentions')
axs[2].set_xlabel('Chapter Number')

# Tweak layout
plt.suptitle('«Dream of the Red Chamber» – Character Mentions per Chapter', fontsize=16, y=1.02)
plt.tight_layout()
plt.savefig('characters_count_separate_bars.png', dpi=300, bbox_inches='tight')
plt.show()


```

## How many times pairs of two protagonists are mentioned together

### Counting and drawing

Threshold (maximum distance between names mentioned) = 20 words.

```{python}
#| label: fig-pairs
#| fig-cap: "Pairs of Two Protagonists"
#| code-fold: true


# Count how many times there is a jia_baoyu_synonyms AND a lin_daiyu_synonyms within 20/threshold characters.

threshold = 20

# Compile regex patterns (non-capturing groups for clarity)
jia_baoyu_pattern = r'(?:' + '|'.join(jia_baoyu_synonyms) + r')'
lin_daiyu_pattern = r'(?:' + '|'.join(lin_daiyu_synonyms) + r')'

# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_lin_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}|{lin_daiyu_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'

# Function to count matches in a string
def count_jia_lin_pairs(text):
    return len(re.findall(jia_lin_pattern, text))

# Apply to the DataFrame
df_cn['JiaBaoyu_LinDaiyu'] = df_cn['RawContent'].apply(count_jia_lin_pairs)



# count pairs of jia et xue

xue_baochai_pattern = r'(?:' + '|'.join(xue_baochai_synonyms) + r')'

# Pattern: 贾宝玉 followed by ≤20/threshold chars then 林黛玉, OR 林黛玉 followed by ≤20/threshold chars then 贾宝玉
jia_xue_pattern = rf'{jia_baoyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{jia_baoyu_pattern}'

# Function to count matches in a string
def count_jia_xue_pairs(text):
    return len(re.findall(jia_xue_pattern, text))

# Apply to the DataFrame
df_cn['JiaBaoyu_XueBaochai'] = df_cn['RawContent'].apply(count_jia_xue_pairs)



# count pairs of lin et xue

lin_xue_pattern = rf'{lin_daiyu_pattern}.{{0,{threshold}}}{xue_baochai_pattern}|{xue_baochai_pattern}.{{0,{threshold}}}{lin_daiyu_pattern}'

# Function to count matches in a string
def count_lin_xue_pairs(text):
    return len(re.findall(lin_xue_pattern, text))

# Apply to the DataFrame
df_cn['LinDaiyu_XueBaochai'] = df_cn['RawContent'].apply(count_lin_xue_pairs)








# Set Chapter_num as index for labeling rows in the heatmap
heatmap_data = df_cn.set_index('Chapter_num')[['JiaBaoyu_LinDaiyu', 'JiaBaoyu_XueBaochai','LinDaiyu_XueBaochai']]

# # Create the heatmap

# Plot the heatmap without labels or annotations
plt.figure(figsize=(10, 6))
sns.heatmap(
    heatmap_data,
    annot=False,          # No numbers inside cells
    cmap='RdPu',
    linewidths=0.5,
    cbar=True,
    xticklabels=True,    #  column names
    yticklabels=False     # No row labels
)

# Set y-ticks at intervals of 25
num_rows = heatmap_data.shape[0]
ticks = np.arange(0, num_rows, 25)
plt.yticks(ticks + 0.5, ticks + 1)  # +0.5 centers ticks in cells, +1 shifts to 1-based indexing

plt.title('«Dream of the Red Chamber» Pairs of Protagonists \n Mentioned Together (per Chapter)')
plt.ylabel('Chapter Number')
plt.xlabel('')  # Remove the x-axis label
plt.tight_layout()
plt.savefig('pairs_characters_hlm.png', dpi=300, bbox_inches='tight')
plt.show()

```

## Similarity matrix

Under construction, it's not very remarkable.

Maybe, removing stopwords ?

```{python}
#| label: fig-similarity
#| fig-cap: "Similarity matrix"
#| code-fold: true
#| echo: false

import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Optional: Use jieba to segment Chinese text
def jieba_tokenizer(text):
    return jieba.lcut(text)

# Segment Chinese text with jieba
df_cn['Segmented'] = df_cn['RawContent'].apply(lambda x: ' '.join(jieba.lcut(x)))

# TF-IDF Vectorization on segmented text
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(df_cn['Segmented'])

# Cosine similarity between chapters
similarity_matrix = cosine_similarity(tfidf_matrix)

# Format as DataFrame for heatmap
similarity_df = pd.DataFrame(
    similarity_matrix,
    index=[f"{idx+1}" for idx in range(len(df_cn))],
    columns=[f"{idx+1}" for idx in range(len(df_cn))]
)



# Plot heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(similarity_df, 
            cmap='RdPu', 
            vmin=0, 
            mask=np.eye(similarity_df.shape[0]), 
            vmax=1,
            linewidths=0.2)

plt.title("«Dream of the Red Chamber» Chapter Similarity Matrix")
plt.xlabel("Chapters")
plt.ylabel("Chapters")
plt.tight_layout()
plt.savefig('similarity_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

```

## Inspirations and further readings

Brown, J. Text Analysis and Data Visualization Assignment: Little Women. *JBrown's Blog* (2010) <https://jbrownsblog.wordpress.com/2010/11/29/text-analysis-and-data-visualization-exercise/>

Heiss, A. PMAP 8921: Data Visualization (2020) <https://datavizm20.classes.andrewheiss.com/example/13-example/>, updated for 2025 <https://datavizsp25.classes.andrewheiss.com/example/14-example.html>

Wang, Z., Huang, D., Cui, J. *et al.* A review of Chinese sentiment analysis: subjects, methods, and trends. *Artif Intell Rev* **58**, 75 (2025). <https://doi.org/10.1007/s10462-024-10988-9>
